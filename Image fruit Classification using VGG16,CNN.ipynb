{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5492146f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG16 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db66b658",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a87018fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load and preprocess images\n",
    "def load_images(folder_path):\n",
    "    images = []\n",
    "    labels = []\n",
    "    class_names = [name for name in os.listdir(folder_path) if not name.startswith('.')]\n",
    "    class_dict = {class_name: i for i, class_name in enumerate(class_names)}\n",
    "\n",
    "    for class_name in class_names:\n",
    "        class_path = os.path.join(folder_path, class_name)\n",
    "        for filename in os.listdir(class_path):\n",
    "            img_path = os.path.join(class_path, filename)\n",
    "            \n",
    "            # Add a check to ensure the image is not empty\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is not None:\n",
    "                img = cv2.resize(img, (224, 224))  # VGG16 input size\n",
    "                img = img / 255.0  # Normalize pixel values to [0, 1]\n",
    "                images.append(img)\n",
    "                labels.append(class_dict[class_name])\n",
    "\n",
    "    return np.array(images), np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06ecc2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate images based on content\n",
    "def remove_duplicates(images, labels):\n",
    "    hash_set = set()\n",
    "    unique_images = []\n",
    "    unique_labels = []\n",
    "\n",
    "    for i in range(len(images)):\n",
    "        img_hash = hash(images[i].tobytes())\n",
    "        if img_hash not in hash_set:\n",
    "            hash_set.add(img_hash)\n",
    "            unique_images.append(images[i])\n",
    "            unique_labels.append(labels[i])\n",
    "\n",
    "    return np.array(unique_images), np.array(unique_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d7abd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "data_folder = 'train'\n",
    "images, labels = load_images(data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "383fca4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates\n",
    "images, labels = remove_duplicates(images, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b71bb04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the data\n",
    "images, labels = shuffle(images, labels, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab6bb5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create data generators for data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "505e59c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the VGG16 model\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(len(np.unique(labels)), activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6593588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the legacy optimizer and specify learning_rate\n",
    "optimizer_legacy = tf.keras.optimizers.legacy.Adam(learning_rate=0.0001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b7dc3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=optimizer_legacy, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "# Set up callbacks\n",
    "checkpoint = ModelCheckpoint(\"best_model.h5\", save_best_only=True)\n",
    "early_stopping = EarlyStopping(patience=10, restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920a3b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "58/58 [==============================] - 501s 9s/step - loss: 2.0204 - accuracy: 0.2315 - val_loss: 1.6142 - val_accuracy: 0.3769\n",
      "Epoch 2/50\n",
      "58/58 [==============================] - 500s 9s/step - loss: 1.3339 - accuracy: 0.4935 - val_loss: 1.1916 - val_accuracy: 0.5882\n",
      "Epoch 3/50\n",
      "58/58 [==============================] - 493s 9s/step - loss: 0.8855 - accuracy: 0.6836 - val_loss: 0.9817 - val_accuracy: 0.7168\n",
      "Epoch 4/50\n",
      "58/58 [==============================] - 486s 8s/step - loss: 0.7186 - accuracy: 0.7473 - val_loss: 0.5715 - val_accuracy: 0.8039\n",
      "Epoch 5/50\n",
      "58/58 [==============================] - 491s 8s/step - loss: 0.5556 - accuracy: 0.7958 - val_loss: 0.6880 - val_accuracy: 0.7865\n",
      "Epoch 6/50\n",
      "58/58 [==============================] - 488s 8s/step - loss: 0.5171 - accuracy: 0.8110 - val_loss: 0.6570 - val_accuracy: 0.8301\n",
      "Epoch 7/50\n",
      "58/58 [==============================] - 490s 8s/step - loss: 0.4642 - accuracy: 0.8410 - val_loss: 0.5226 - val_accuracy: 0.8344\n",
      "Epoch 8/50\n",
      "58/58 [==============================] - 489s 8s/step - loss: 0.3387 - accuracy: 0.8894 - val_loss: 0.5019 - val_accuracy: 0.8453\n",
      "Epoch 9/50\n",
      "58/58 [==============================] - 490s 8s/step - loss: 0.2773 - accuracy: 0.9080 - val_loss: 0.3690 - val_accuracy: 0.8736\n",
      "Epoch 10/50\n",
      "58/58 [==============================] - 489s 8s/step - loss: 0.2454 - accuracy: 0.9145 - val_loss: 0.3677 - val_accuracy: 0.8867\n",
      "Epoch 11/50\n",
      "58/58 [==============================] - 488s 8s/step - loss: 0.2675 - accuracy: 0.9107 - val_loss: 0.4592 - val_accuracy: 0.8606\n",
      "Epoch 12/50\n",
      "58/58 [==============================] - 500s 9s/step - loss: 0.2303 - accuracy: 0.9194 - val_loss: 0.2945 - val_accuracy: 0.9259\n",
      "Epoch 13/50\n",
      "58/58 [==============================] - 492s 8s/step - loss: 0.2170 - accuracy: 0.9336 - val_loss: 0.3581 - val_accuracy: 0.8911\n",
      "Epoch 14/50\n",
      "58/58 [==============================] - 498s 9s/step - loss: 0.1564 - accuracy: 0.9515 - val_loss: 0.4452 - val_accuracy: 0.8758\n",
      "Epoch 15/50\n",
      "38/58 [==================>...........] - ETA: 2:37 - loss: 0.2284 - accuracy: 0.9256"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_datagen.flow(X_train, y_train, batch_size=32),\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=50,\n",
    "    callbacks=[checkpoint, early_stopping]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2566d3a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf8078d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Function to load and preprocess images\n",
    "def load_images(folder_path):\n",
    "    images = []\n",
    "    labels = []\n",
    "    class_names = [name for name in os.listdir(folder_path) if not name.startswith('.')]\n",
    "    class_dict = {class_name: i for i, class_name in enumerate(class_names)}\n",
    "\n",
    "    for class_name in class_names:\n",
    "        class_path = os.path.join(folder_path, class_name)\n",
    "        for filename in os.listdir(class_path):\n",
    "            img_path = os.path.join(class_path, filename)\n",
    "            \n",
    "            # Add a check to ensure the image is not empty\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is not None:\n",
    "                img = cv2.resize(img, (224, 224))  # VGG16 input size\n",
    "                img = img / 255.0  # Normalize pixel values to [0, 1]\n",
    "                images.append(img)\n",
    "                labels.append(class_dict[class_name])\n",
    "\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Remove duplicate images based on content\n",
    "def remove_duplicates(images, labels):\n",
    "    hash_set = set()\n",
    "    unique_images = []\n",
    "    unique_labels = []\n",
    "\n",
    "    for i in range(len(images)):\n",
    "        img_hash = hash(images[i].tobytes())\n",
    "        if img_hash not in hash_set:\n",
    "            hash_set.add(img_hash)\n",
    "            unique_images.append(images[i])\n",
    "            unique_labels.append(labels[i])\n",
    "\n",
    "    return np.array(unique_images), np.array(unique_labels)\n",
    "\n",
    "# Load and preprocess data\n",
    "data_folder = 'train'\n",
    "images, labels = load_images(data_folder)\n",
    "\n",
    "# Remove duplicates\n",
    "images, labels = remove_duplicates(images, labels)\n",
    "\n",
    "# Shuffle the data\n",
    "images, labels = shuffle(images, labels, random_state=42)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create data generators for data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Create the VGG16 model\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(len(np.unique(labels)), activation='softmax'))\n",
    "\n",
    "# Use the legacy optimizer and specify learning_rate\n",
    "optimizer_legacy = tf.keras.optimizers.legacy.Adam(learning_rate=0.0001)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=optimizer_legacy, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "# Set up callbacks\n",
    "checkpoint = ModelCheckpoint(\"best_model.h5\", save_best_only=True)\n",
    "early_stopping = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_datagen.flow(X_train, y_train, batch_size=32),\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=50,\n",
    "    callbacks=[checkpoint, early_stopping]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9f08dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
